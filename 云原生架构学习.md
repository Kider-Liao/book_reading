## 序章

1. 云原生的意义：云原生技术大大降低了数字化的门槛，使得研发和运维人员，以及他们所服务的企业能够专注业务本身，使得企业能够在短时间内实现面向全球几十亿人的服务能力。云原生是数字化这一时代大潮的技术推动力

2. 应用设计考虑的三个维度：应用所需要的系统资源；应用自身的架构模式(从传统的单体架构模式到后来的微服务模式、服务网格)；云原生应用的设计、开发、部署、运维等不同阶段(应用的生命周期)

3. 云原生应用的含义：从最初便设计为在云上以最佳方式运行的应用，应能够充分发挥云平台的各种优势



## 第一部分：系统资源



#### 第1章 操作系统

1. 分层技术：计算机领域设计中最常用的技术之一，设计者常使用分层的思想解构复杂的系统。分层模型中不同层次代表不同的抽象级别，底层负责具体功能的实现，并向上一层提供一个**抽象接口**，为上层提供服务。分层技术使得模型每层只需要关心自身的业务逻辑，不考虑其他层次的具体实现，**降低了系统设计的复杂性以及提升软件的可移植性**。

2. 操作系统的典型分层示例(自底向上)

   - 硬件：提供计算能力、存储能力以及输入\输出等功能的物理设备
   
   - CPU指令集：软件控制CPU的接口，CPU对指令进行解码，控制计算、存储单元进行相应的工作
   
   
      - 操作系统：管理系统硬件、软件的系统**软件**程序，为上层应用提供系统级的功能集合，对底层硬件进行防护和调度管理
   
   
      - 系统调用：调用操作系统为上层应用提供的功能集合，是用户态转变为内核态的唯一入口，是上层应用与操作系统交互的接口(最小的功能)
   
   
      - 函数库：操作系统已实现的封装了系统调用的对底层硬件、内核等进行调用的方法。函数库中实现的方法具有不同的功能，应用程序通过调用相应的方法满足自身的功能需求
   
   
      - 应用程序：借助底层提供的功能，实现不同的业务逻辑功能
   
3. 函数库与系统调用的重要区分

   ![image-20220802171330699](C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220802171330699.png)

4. 操作系统主要功能(操作系统对下管理硬件资源，对上为应用程序提供功能接口)

   - 资源接入与抽象：将CPU、内存等设备抽象成可识别的逻辑资源
   
   
      - 资源分配与调度：将抽象出来的逻辑资源按需分配给不同的应用
   
   
      - 应用生命周期管理：实现应用安装、升级、启动、停止、卸载等管理操作
   
   
      - 系统管理和维护：协助系统管理员进行对系统自身的配置、监控和升级等管理操作
   
   
      - 人机交互与支持：提供必要的人机交互界面，且支持管理员和用户对系统进行操作
   
5. x86体系下的指令集

   - 特权指令(操作和管理关键系统资源的指令)：允许和禁止中断、进程切换、存取寄存器、执行IO操作、停止一个中央处理器的工作、清理内存、设置时钟、加载程序状态字、建立存储键
   
   
      - 非特权指令：不改变系统状态的除特权指令外的指令
   
   
      - 保护模式：CPU内状态寄存器用两个比特位标识当前的保护模式，因而保护模式分为4种特权级别。Linux中只用到了Ring0(内核态)和Ring3(用户态)，Ring0级别下执行的指令具有访问所有计算机资源的权限
   
   
      - 用户态转化为内核态：当应用运行在用户态时，如果执行的指令有操作系统资源等危险行为，会通过操作系统的内陷Trap机制转到内核态，执行相应的系统资源操作。指令完成后再转为用户态。用户态转化为内核态的触发条件主要为系统调用、异常处理、硬件中断
   
6. 操作系统内核基础

   - 内核模块：多段计算机程序的结合，直接管理系统资源，并把资源抽象后提供给应用使用
   
   
      - 内核的运行：内核中的各个功能模块都作为单独的进程运行，模块之间通过消息传递进行通信
   
   
      - 内核不同功能模块的整合：静态编译，即在编译阶段将所有功能都编译进内核，这样不会出现兼容性问题，但是会出现内核过大、内核修改需要整个重新编译的问题；动态加载，即将功能编译成模块，在需要时动态加载。这样减少了内核的大小，并增加内核模块的弹性，缺点是性能上可能出现缺失
   
7. 内核架构类型

   - 单内核：又称“大内核”，是一个单独的二进制映像，包含了操作系统的所有功能(进程调度、文件系统、网络服务、存储管理、设备驱动等)。内核程序本身将作为一个很大的进程存在，进程内的所有服务都运行在同一个地址空间，通过函数调用进行模块间通信。单内核体系结构简单高效，但模块之间调用过于繁杂，系统修改和升级时相互影响

   
   - 微内核：在内核中保留必要的服务，如调度计算资源、管理内存资源等，将其他的模块功能以服务扩展件的形式存在。用户可以根据需要加载相应的服务扩展件，且这些功能模块的升级只需要直接用新模块进行替换即可。微内核架构具有良好的扩展性，且减少了内核对磁盘和内存的需求。
   
   
   - 外内核：(没能理解其原理，该架构目前处于实验阶段)



#### 第2章 虚拟化

1. 三类常见计算机资源：计算资源(服务器CPU、内存等)、存储资源(磁盘空间等)、网络资源(网卡、路由器等)

2. 直接使用物理设备带来的不足

   - 缺乏时间灵活性：系统资源匮乏时，需要扩容资源，而物理设备的安装设置繁琐，导致时间灵活性差。即生产或销毁物理设备资源的时间效率底下
   - 缺乏空间灵活性：可以使用的资源规模大小不灵活，容易导致服务器资源利用率过剩等问题
   - 缺乏操作灵活性：大规模物理集群的运维难度高，设备上架、安装、配置等都需要大量工作
   - 隔离性差：若多个服务部署在同一台物理设备上，容易导致服务之间相互干扰的问题
   - 不可复制：一个物理设备上的应用需要进行水平扩展时，只能通过复制整个物理设备来实现

3. 广义虚拟化概念

   - 硬件虚拟化(注意这类虚拟化概念与系统虚拟化的不同)：将硬件层进行抽象，虚拟化为相同或相似的抽象硬件层，从而使得操作系统及以上的层可以快速移植到不同的硬件资源上。如Windows操作系统可以从苹果笔记本方便地移植到华为笔记本上。
   - 内存虚拟化：对内存空间进行虚拟化，令应用程序使用虚拟内存，突破物理内存的限制
   - 系统虚拟化(我们常说的狭义虚拟化特指操作系统虚拟化)：在一台物理机上模拟出多台隔离的虚拟机，且逻辑上每台虚拟机都具有独立的资源，运行着独立的操作系统Guest OS。虚拟化资源以虚拟机的形式提供给用户，**虚拟机是为其他应用软件提供虚拟化环境的最小单元(目前的容器技术是否打破了这个定义)**
   - 应用虚拟化：在应用层以及函数层之上建立抽象层，提供逻辑隔离功能，允许在一个应用上同时支持多个用户使用(即多租户技术)。例如一个数据库可以被分为隔离的多个逻辑数据库

4. 虚拟化特征：分区(单一物理机上运行多台虚拟机)、隔离(多台虚拟机相互隔离)、封装(虚拟机的执行环境，包括硬件、操作系统等都被封装在独立文件中)、独立(虚拟机可以不加修改地迁移到其他服务器上运行)

5. 虚拟化指令集

   - 二进制翻译技术：将某个硬件平台的二进制代码转换为另一个平台的二进制代码，实现不同指令集之间的兼容，针对虚拟化漏洞指令

   - 敏感指令集：操作特权资源的指令，包括修改虚拟机的运行模式，改变宿主机的状态，读/写时钟、中断等寄存器，访问存储保护系统、地址重定位系统以及所有的I/O指令。这类指令会影响基于虚拟化的整个系统的安全

   - 有效的虚拟机监视器的特性(Popek＆Goldberg原理)：等价性，即任何一个程序除时序和资源可用性外，其他的运行应当不受到管理程序的约束，而且预置的特权指令可以自由执行；资源控制，即一个程序发出的任何调用系统资源的动作在被执行时，都应先调用控制程序；效率性，即程序发出的无害指令应当由硬件直接执行，"穿透"虚拟机监视器

   - 敏感指令执行(敏感指令都是特权指令)：在虚拟机中执行内核态的特权指令时，会通过陷阱机制被下层的虚拟机监视器捕获。虚拟机监视器对捕获的特权指令进行替换操作，从而完整地模拟出某个虚拟机监视器下的特权操作。具体的流程为

     <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220803170309936.png" alt="image-20220803170309936" style="zoom:50%;" />

   - 优先级压缩技术：虚拟机监视器采用优先级压缩技术，使得虚拟机中的应用运行在Ring3层，Guest OS内核运行在Ring1层，虚拟机监视器运行在Ring0层。优先级压缩下，Guest OS的部分内核指令在Ring1或Ring3下无法执行，此时可以通过"陷阱+模拟"机制执行。在这种情况下，对于虚拟机中的应用需要操作重要资源时，特权指令先通过陷阱陷入Guest OS内核态中运行，若出现在Ring1级别无法执行的指令时，再陷入到虚拟机监控器模拟执行，从而出现两次特权下降的现象。

6. 虚拟化类型

   - 全虚拟化：虚拟机监视器模拟出来的平台是一个完备的运行环境，Guest OS不需要做任何修改即可在全虚拟化平台上运行(因此称为全虚拟化)，要求全虚拟化平台能够正确处理所有的敏感指令。对于特权指令，采用"陷阱+模拟"的方式，模拟特权指令的执行；对于非特权指令的敏感指令，Ring0下的虚拟机监视器通过二进制代码扫描并替换Ring1下的Guest OS的二进制代码，把所有虚拟化漏洞指令替换成其他指令，实现虚拟化。全虚拟化劣势在于实时的内存扫描造成了虚拟机性能受到很大的损耗

   - 类虚拟化：类虚拟化的Guest OS知道自己运行在虚拟化环境中，且需要修改内核代码来规避虚拟化漏洞的问题。Guest OS会将与敏感指令相关的操作都转化为对虚拟机监视器的超级调用Hypercall，将敏感指令主动提交给虚拟机监视器进行处理。超级调用支持批处理和异步两种优化方式，使得类虚拟化技术能够得到近似物理机的速度。超级调用类似于操作系统提供的系统调用。类虚拟化只能使用虚拟机监控器专属的虚拟机镜像

   - 硬件辅助虚拟化：引入root模式和no-root模式，两者都能运行在Ring0~Ring3下。虚拟机监视器运行在root模式下的Ring0(也称为Ring -1)，Guest OS运行在no-root模式下的Ring0。通常情况下，Guest OS的特权指令可以直接下达到计算机系统硬件执行，而不需要通过虚拟机监视器。当Guest OS执行敏感指令时，系统会切换到虚拟机监视器，让其处理敏感指令。部分特权指令的直接下达使得硬件辅助虚拟化技术性能大大提高

     在硬件辅助虚拟化下，虚拟机监视器和Guest OS的执行环境完全隔离开，通过新的指令实现两种环境之间的相互转换。若在no-root模式下执行了敏感指令或发生了中断等，则会通过VMExit退出no-root模式，并把详细的中断信息保存在VMCS寄存器中。虚拟机监视器随后确认虚拟机退出的原因，执行相关操作，并把结果发送回虚拟机，转为no-root模式执行后续操作

     **问题：如果不在Guest OS上做修改，其运行敏感指令或发生中断时，其为何会执行VMExit指令退出到root模式。是由于硬件指令集的修改，使这些敏感指令跟中断的操作变为执行VMExit吗**

7. 虚拟化架构

   - 裸金属架构：虚拟机监视器直接安装和运行在物理机上，通过其自带的轻量级内核管理物理机上的硬件资源。虚拟机监视器自包含有硬件的驱动程序，不依赖于特定的操作系统，可以直接分配和管理硬件资源，但支持的硬件设备依赖于其自包含的内核
   - 宿主模式架构：虚拟机监视器作为一个应用被安装和运行在操作系统上，依赖宿主操作系统的内核使用硬件设备和管理硬件资源。依赖于宿主操作系统的虚拟机监视器对硬件资源的访问必须通过宿主操作系统，效率降低，但是可以利用宿主操作系统支持更多设备，使用内存管理、进程调度等服务，不需要自包含管理资源的内核，减小虚拟机监视器的大小



#### 第3章 云计算

1. 虚拟化的不足

   - 缺乏时间灵活性：虚拟化并非随时随处可用，服务商无法随时保证服务的可用性，且虚拟化需要比较复杂的人工配置，难以实现大规模的配置
   - 缺乏空间灵活性：虚拟化需要人工指定将虚拟机放在哪台物理服务器上，缺乏分布式部署，无法实现资源的自动化弹性扩展
   - 缺乏操作灵活性：虚拟机创建需要人工配置，未能实现自动化部署，虚拟化缺乏统一的自动化管理

   云计算与虚拟化相比，通过调度器来管理大量物理服务器抽象而来的虚拟资源池，并根据用户需求在资源池中自动化匹配最合适的资源，通过虚拟机的形式配置并供给资源。

2. 云计算的特点

   - 按需自助：用户无需与服务提供商交互，可以自动地得到资助的计算资源

   - 访问无边界：在不同客户端、任何时间地点均可以通过网络访问计算资源

   - 资源池化：将所有物理机上的网络计算资源视为整个资源池进行资源的划分，根据用户需求动态划分或释放不同物理资源和虚拟资源。服务商的网络资源对外表现为一个包含大量CPU、内存等资源的资源池，这些计算资源以多租户的模式来提供服务

   - 极速伸缩：对资源快速和弹性提供的能力以及释放的能力，能够根据用户负载和需求变化快速地伸缩分配的资源

   - 量化服务：能够监测和控制资源的使用，通过计量的方法检测用户资源的使用情况，监测服务效果，为供应商和用户提供透明的报告

3. IaaS：资源池化、自动化管理和分配资源的虚拟化技术(解决了虚拟化技术三个灵活性问题)

   - 常见的云部署模式
     - 私有云：将虚拟化软件和云控制平台等部署在用户的数据中心，即用户提供场地和服务器，由云厂商在服务器上部署云平台
     - 社区云：将虚拟化软件和云控制平台等部署在具有共同愿景(合作关系或需求相同)的组织集体的内部或外部，由组织集体内的用户进行使用
     - 公有云：将虚拟化软件和云控制平台等部署在云厂商自身的数据中心，开放给外界用户使用。外界用户只需要注册账号，就可以通过Web服务访问、管理云资源。公有云具有大规模、敏捷性、弹性等优势，但是其安全性是需要解决的重要问题
     - 混合云：私有云、社区云和公有云的有机结合，将不同安全等级的应用部署到不同的云上。通过将主要业务部署在私有云，备用业务部署在公有云，将公有云的弹性、敏捷性和私有云的安全性、私密性结合。
     
   - IaaS的主要功能
     - 资源接入与抽象：将底层虚拟化资源抽象为可识别的计算、存储、网络等资源池，以此作为云控制器对各类硬件资源实施管理的基础(资源池化管理)，自动化管理资源加入或退出资源池
     
       **操作系统的抽象是将存储器抽象为地址空间、CPU抽象为执行指令的控制器等，IaaS中控制器的抽象是将多个物理机的CPU、存储统一为一个包含N核MGB存储等的大型资源池**
     
     - 资源分配与调度：利用云平台调度器，按照不同用户的资源需求，在资源池中分配合适的资源给用户
     
     - 应用生命周期管理：协助用户实现虚拟机在云上的安装、启动、停止、卸载等操作
     
     - 云平台管理维护：由云平台管理员实施对整个云平台的管理和运维操作
     
     - 人机交互支持：提供人机交互界面，支持云平台管理员和普通用户对云平台的操作使用
     
   - IaaS架构
     - 物理资源层：IT基础设施硬件，包括计算设备(服务器)、存储设备、网络设备等
     - 虚拟化资源层：将分布在不同物理设备上的基础设施资源进行统一虚拟化，构成计算资源池、存储资源池、网络资源池等，利用虚拟化技术向上屏蔽资源分布、分配、调用等细节
     - 云服务控制层：为运行的应用提供基本的API，将池化的计算、存储、网络等资源作为基本资源单位，向上层提供统一的调用接口。同时还实现了虚拟资源的调度逻辑，让上层应用更有效地使用资源(该层实现了资源调度、弹性伸缩、软件定义存储等控制，属于云平台的控制层)
     - 云管理层：基于云服务控制层的API实现多云的异构纳管，打通不同的云服务。通过把原先的云控制平台作为计算、存储、网络资源池，提供统一的租户管理，实现不同云控制平台之间的资源统一管理和资源跨越统一编排，对外提供统一API(将多个云控制平台资源进行整合，提供统一的API进行操作)
     - 运维层：运维包括云平台模块的安装，部署已有补丁的升级包，物理设备层、虚拟化层以及服务层的监控与故障管理，日志管理，自动化测试等，确保整个平台的可靠性、可用性、性能等，且达到服务级别协议SLA中用户的要求
     - 安全层：负责云平台各层的安全，包括物理安全、主机安全、数据安全等等
     
   - 云平台组织架构
   
     - 资源组织架构：资源组织架构分为服务区、可用区和资源池。整个云平台由多个服务区组成，每个服务区都对应一个云管理平台，但共享一组服务产品目录。服务区的模式往往用于公有云中，为处于不同地区的用户提供云服务；每个服务区由多个可用区组成，每个可用区都对应一个物理上独立的云控制平台，由一个或多个物理上临近的数据中心构成；每个可用区都包含多个资源池(一组同构的物理设备)，由可用区的云控制平台进行管理
   
       **在华为云上购买服务器时，可以明确看到服务区、可用区之分。临近的服务区有助于降低网络延时，提升带宽；可用区是在同一区域下，电力、网络隔离的物理区域，在同一服务区中的可用区内网互通。但是由于可用区物理隔离的特点，不同可用区的可行性和可靠性分离，因此服务部署在不同可用区有助于提高容灾能力，但部署在同一可用区可以降低延时**
   
     - 用户组织架构：用户组织架构分为虚拟数据中心和虚拟私有云。虚拟数据中心是虚拟私有云的上一层组织关系。租户占用的资源区域称为虚拟私有云，而一个虚拟数据中心可以包含多个租户的资源区域。虚拟数据中心可以对其内部使用的不同资源进行配额管理，而虚拟私有云将虚拟数据中心的资源划分为多个区域，并提供隔离环境和网络边界防护。个人理解是虚拟数据中心是一组资源的拥有者，在将资源分配给不同租户后，形成了计算和网络隔离的区域，生成了多个虚拟私有云。虚拟私有云是多租户环境下分配给一个用户的资源的拥有者，并提供了资源的隔离边界。
   
   - Openstack：书中只讲了一些基本的各个组件的作用以及Openstack的由来等，还需要之后具体地学习
   
4. PaaS：平台即服务

   - PaaS简介：PaaS在基于IaaS提供了虚拟化资源的基础上，应用这些虚拟化资源自动化部署了应用运行时所依赖的库、工具、服务、运行时环境等。PaaS核心理念是由PaaS负责维护底层虚拟化资源的稳定性，用户只需要在PaaS上部署应用，让用户把更多精力投放在应用开发上。相比IaaS，减少了用户使用的复杂度和日常维护的工作量，为用户提高了更高层的资源抽象。
   - PaaS工作模式(理想状况)：应用开发者通过PaaS平台GUI提供的标准开发工具进行代码开发，提交应用代码，PaaS平台的代码托管工具进行代码的编译、打包。PaaS的自动化部署模块将打包好的代码部署在IaaS提供的虚拟机上，设置好代码的运行环境。一旦代码部署完毕，PaaS会自动为应用提供依赖的外部服务，从而确保应用正常运行。运行过程中，PaaS平台还会自动接入日志、监控等非核心业务服务，提升应用的可恢复性和可检测性等，保障应用的运行
   - PaaS平台组成成分
     - 应用的运行环境：应用运行节点上所需的运行环境，包含编程语言环境、应用框架等，以及运行环境所需的资源隔离和限制。在运行环境方面，PaaS平台需要实现对虚拟化资源(CPU、内存等)的管理以及对应用资源使用情况的管控；PaaS平台需要能够完成对应用的自动化部署；PaaS平台需要能够根据负载的变化，增减应用的实例数，实现弹性伸缩
     - 应用的内部支撑服务：主要负责应用的认证授权、运维监控、日志管理等
     - 应用的外部依赖服务：为应用提供的外部服务，包括数据库、缓存、中间件等，可能还需要大数据、NoSQL、机器学习等服务
   - PaaS核心功能
     - 自动化部署：PaaS提供了自动化编译、打包、部署的核心能力。像Cloud Foundry这样的PaaS项目，其在编译完毕应用后，将应用的可执行文件和启动脚本打包到一个压缩包内，上传到云上Cloud Foundry的存储中，由Cloud Foundry的调度器选择一台可以运行这个应用的虚拟机，由该虚拟机的代理下载压缩包并启动运行
     - 多副本管理：多副本机制将应用以及相关数据复制到不同节点上，通过冗余的方式增强服务的可靠性，需要进行副本数据的同步。同步方式有推和拉两种，推是从数据源向各个副本推送更新数据，拉是由各个副本根据同步算法从数据源拉取更新数据
     - 弹性伸缩：PaaS自动为应用进行弹性伸缩，确保应用服务的高可用性。PaaS通过负载均衡器将用户请求分发到该云服务的不同实例上，当负载均衡器认为负载超过当前云服务的上限时，它将会通知云编排器。云编排器在新的相同的虚拟机实例上调用相同的部署工具部署应用，将新的实例上报到负载均衡器。负载均衡器将会将新的请求转发到新的实例上。当负载较小时，只会维护最低要求的副本数
   - PaaS的优缺点
     - PaaS优点为：高灵活性(应用自动化部署，操作简易)、高可用性(多副本)、高性能(弹性伸缩)、隔离性(多租户逻辑隔离或物理隔离)
     - PaaS缺点为：PaaS技术使得应用与PaaS平台有非常强的耦合性，用户必须依赖PaaS平台提供的框架和中间件来实现自己的应用，使得应用开发人员失去了底层环境和资源的控制力，限制较多。
   
5. SaaS以服务的形式对外提供应用程序，其本质等同于通过SOA形式对外暴露服务，供用户使用。但是大部分的SaaS不是基于PaaS开发的，而是直接在IaaS上开发。供应商将一个已经实现好的应用程序部署在自己的虚拟机上，并对外暴露一个服务接口，向用户提供服务。例如：云计算厂商将自己设计好的经过大量数据训练的人工智能程序部署在云平台上，对外暴露一个服务接口，直接供用户使用。



#### 第4章 容器

1. 容器概念：容器是一种打包应用及其运行环境的方式，为应用打包所有软件及其依赖的运行环境，并且可以做到跨平台部署。容器的环境是自包含的，只要环境上装有docker这类运行容器的应用，容器就可以在这个环境运行。

2. 容器的优缺点

   - 轻量化：相比虚拟机需要完整的操作系统，容器镜像更小，只包含了少量的必要的依赖，使得可以快速对容器进行构建和启动。容器更适合批量快速上线和快速弹性伸缩的应用

   - 细粒度(资源管控)：在创建容器时，可以指定其可用的CPU、内存等资源，使得在容器运行时能够执行这些资源限制，防止容器占用过多资源

   - 高性能(资源利用率高)：容器使用更轻量级的运行机制，是操作系统级别的虚拟化，以进程的形式运行。这使得应用的性能接近于裸机的性能，适合于对性能要求高的应用

     **问题：容器的运行效率为什么比虚拟机更高，虚拟机具体的性能损失在哪(与VMM的交互？)**

   - 环境一致性：容器实现了自身与宿主操作系统的解耦，其自包含了运行环境，使得应用运行的本地环境在任何运行环境下都保持一致，从而保证了一次容器的打包可以到处运行，不依赖于宿主的环境

   - 管理便捷性：容器的生命周期管理，包括迁移、扩展、运维等更加便捷

   - 安全性差：容器只提供进程级别的隔离性，共享宿主操作系统的内核，其安全性较差

3. 容器的关键技术

   - namespace：容器基于Linux的namespace技术，为每个应用进程都创建了一个完全隔离的环境。namespace使得PID、IPC、network等系统资源不是全局性的，而是属于特定的namespace的。位于同一namespace的进程对资源的视图是一致的，每个namespace中的资源对其他的namespace都是透明的、互不干扰的。namespace技术使得创建的容器进程只能看到当前namespace限定的资源、文件、设备等，与外界实现了视图的隔离。下面列举系统中几种重要的namespace

     - PID namespace：如果在调用clone时设置了CLONE_NEWPID，就会为派生的进程创建一个新的PID namespace，这个进程空间的PID将会重新开始计算，与外界分隔，使新进程看到全新的进程空间。新进程将成为该namespace中的第一个进程，PID为1，该namespace中的其他进程都是新进程的子进程，新进程结束时其他的进程都会结束。PID namespace是有层次的，新创建的namespace会是创建该namespace的进程所属的namespace的子namespace。子namespace中的进程对父namespace是可见的，使得一个进程在其本身的namespace以及在所有父namespace中都有一个PID。系统启动时会有一个默认的PID namespace，它是所有namespace的祖先

     - IPC namespace(IPC与进程通信关联)：如果在调用clone时设定了CLONE_NEWIPC，将会创建一个新的IPC namespace，新建的进程称为IPC namespace中的第一个进程。位于不同IPC namespace中的进程无法直接通信。IPC namespace的创建能与PID namespace的创建组合，使得不同namespace之间的进程既不能通信又不能看到其他进程的PID，实现进程的隔离

       **问题：如果子进程与父进程IPC namespace不同，能否进行通信(推断是不能)**

     - mount namespace(mount为挂载操作，将某个磁盘、光驱等挂载在文件夹上，使得访问该文件夹即可访问磁盘、光驱等的内容)：如果在调用clone时设定了CLONE_NEWNS，就会创建一个新的mount namespace。mount namespace提供了独立的挂载点列表，使得在当前namespace中的进程不能看到其他namespace的挂载点信息，且其他进程也不能看到该namespace的挂载点信息。mount namespace配合chroot、pivot_root，可以为进程创建一个独立的文件系统

     - network namespace：如果在调用clone时设定了CLONE_NEWNET，即可创建一个新的network namespace，为进程提供一个完全独立的网络协议栈视图，其中包括网络设备接口、IPv4和IPv6协议栈、IP地址路由器、防火墙规则、Socket等。新建的network namespace需要通过分配IP，与虚拟网卡绑定等操作，才能与外界进行通信

     - UTS namespace(主机名和域名等的隔离)：如果在调用clone时设定了CLONE_NEWUTS，就会创建一个新的UTS namespace，即系统内核参数namespace。新建的namespace通过复制调用进程所属的namespace的标识符进行初始化，此后其内部标识符的修改对外是不可见的。例如，新的namespace调用sethostname改变了namespace的主机名，这个操作只对该namespace内的所有进程可见。

   - cgroup：在namespace基础上，虽然进程在视图上进行了隔离，但是在宿主机上，它们资源的使用仍旧是共享的，这可能导致部分进程占用CPU、内存过高导致其他进程无法正常使用的问题。cgroup的出现为进程的资源限制提供了有效的方法。cgroup通过对进程进行分组，并在分组的基础上限制进程组能够使用的各种资源的上限，从而能够对进程组内进程的资源使用进行监控和限制。

     cgroup技术将系统中的所有进程组织成进程树，树中的每个节点都是一个进程组，每个进程组被授予了不同的资源限制。系统中可以有多个进程树，每个进程树都关联了一种或多种受限的资源。

   - rootfs：rootfs技术应用的是Linux中的chroot命令，它的作用是将进程的根目录变更到指定的位置，使其看到的文件系统受限。通过chroot为容器提供一个新的根目录，在根目录下挂载一个完整的操作系统，并在操作系统上安装容器所需的依赖，使得容器有了与外界隔离的独立的运行空间，从而容器能够运行在任何一台宿主机上，解决了过去因本地开发环境与远端运行环境不一致导致的问题。rootfs实际上就是这个挂载在容器根目录下的文件系统，即容器镜像，它的内容不包含操作系统的内核，这使得运行在同一宿主机上的容器共享了宿主机的操作系统内核。

     Docker镜像的制作并没有沿用rootfs制作的标准流程，而是在镜像制作中引入了层的概念。用户的每一步操作都会生成一个层，整个镜像以增量的形式逐步形成目标镜像(这个增量机制基于Linux的UnionFS技术)。Docker的镜像主要分为只读层(镜像底5层，包括基础镜像文件等)、可读/写层(镜像最上层，记录用户对容器修改产生的增量内容，可以通过commit和push命令保存当前容器的rootfs为新镜像)、init层(位于只读和可读写层之间，保存了启动容器时自动写入的一些配置文件，不属于只读层是因为这些文件是与容器关联的)。增量式的镜像使得多个镜像可以共享部分内容，节约了大量的存储空间，且镜像拉取、推送内容所需的空间比推送完整的镜像所需的空间要小很多(只需要拉取可读写层)。

4. Docker：使用最广泛的容器运行时管理工具，基本思想是隔离运行应用的进程和监督容器的生命周期以及资源使用

   - 容器运行时：主要包括libcontainer、runC和containerd三个部分

     - libcontainer：Docker通过libcontainer库与Linux内核功能进行交互(Docker并没有实现更多的内核技术，其核心技术都依赖于Linux内核技术)，进行容器的生命周期管理，为容器形成隔离环境
     - runC：为Docker进行底层容器管理，用于创建和运行容器(功能包含环境隔离、资源限制等)。runC更加轻便、快速，但只用于运行容器。runC包含了libcontainer库，用于调用Linux内核功能
     - containerd：为Docker进行上层容器管理，负责容器生命周期的管理，包括镜像传输和存储(直接用runC需要自行准备容器文件系统)、容器的运行与监控、底层存储、网络附件管理等

     容器运行时的整体工作流程为

     <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220806223102898.png" alt="image-20220806223102898" style="zoom: 67%;" />

   - Docker镜像：Docker镜像事实上就是一个包含了完整操作系统以及其他应用依赖的压缩包，封装整个环境的运行环境，使得应用在开发环境和生产环境中部署时的运行环境是一致的，解决了应用在开发环境和生产环境运行不统一的问题。

5. 内核容器技术：解决容器安全隔离性的问题

   - Kata：Kata采用传统的虚拟化技术，模拟出一台虚拟机，用虚拟机控制器Hypervisor对硬件资源进行管控，并使用一个带内核的轻量级操作系统，用于在虚拟机内部署容器。为每个容器分配一个Guest OS，使运行在虚拟机上的容器事实上只能看到虚拟机的Guest OS，因此容器只能看到一个极小的、独立的、以容器为单位的操作系统内核，攻击面变窄，增加了安全性

     (个人观点：Kata改进点在于用小型的具有带内核的操作系统的虚拟机去部署容器，使得容器无法共享宿主机内核，获得了操作系统级别的隔离性)

   - Firecracker：原理与Kata相同，只是使用了自己编写的虚拟机监视器

   - gVisor：采用一个运行在用户态的"独立内核"，即一个模拟内核的系统组件(称为Sentry的进程)。Sentry使用KVM进行系统调用的拦截，将容器进程使用到的系统调用拦截下来后交给Sentry处理，即将容器进程的系统调用等资源操作统一由用户态内核处理，避免了容器进行系统调用等操作危害宿主机内核的情况。



#### 第5章 容器编排

1. 容器编排概念：容器编排是指自动化管理和协调容器的能力，实现了容器的生命周期管理(Docker主要是在单节点上的容器管理)

2. 容器编排工具核心功能

   - 资源管理：将一组服务器视为CPU、内存和存储卷等构成的资源池，进行资源管理
   - 调度和编排：调度指根据某种规则将容器放置在某个最佳的运行节点上运行；编排是指根据给定模板和用户的意愿，自动化创建和组合容器，处理容器间的关系，并对其进行生命周期的管理
   - 服务管理：为运行的应用提供额外的支撑性服务，如负载均衡、应用安全等

3. Kubernetes设计理念与特性

   - 一切皆为对象：所有信息都是以API对象的形式存储在etcd(分布式存储系统)中，所有操作都是对API对象的操作。同时，Kubernetes通过使用一种API对象(如Deployment)来管理另一种API对象(如Pod)，全面使用对象实现业务建模。API对象的类别和信息会在之后进行具体介绍

   - 声明式API：声明式API是指用户只需要提交一个根据模板定义好的API对象来说明应用最终的运行状态，由Kubernetes的controller、scheduler等自动进行资源分配、容器创建等，以达到用户要求的最终状态。Kubernetes通过YAML文件来表达应用的最终运行状态，并自动对应用进行运维和管理

     **问题：书本中提到声明式API具有多个API写端，以PATCH的方式对API对象进行修改，而无需关心YAML文件的内容，这个特点还没能理解它是什么意思(推测是批量修改API对象的能力)**

   - 切面式管理：Kubernetes通过控制器模式实现切面式管理和职责划分。切面式管理主要在于Kubernetes的控制器能够对API对象进行完整生命周期管理。通过循环比对探测到的实际状态与期望状态，计算出两者的差值，并执行相应的操作，从而确保实际状态能够趋向期望状态。控制器模式使得Kubernetes能够完成对容器生命周期进行管理，能够时刻监控并维持API对象处于期望状态；职责划分主要在于Kubernetes通过使用不同的控制器负责不同方面的管理，使得不同方面之间相互协调、共同协作，向期望状态逼近。

     **控制器模式能够实现全生命周期管理，在于控制器需要时刻检测API对象的状态，使其维持终态，这是声明式API为Kubernetes带来的重要优势；相反，命令式API要求API对象时刻根据指令进行运作，API对象的生命周期往往与用户发送的指令相联系，指令直接影响到API对象的行为，使得控制器无法实时保障API对象的生命周期**

     **这里书本提到的切面式管理以及"面向切面编程"模式似乎不太准确，面向切面编程指的是找到代码中与核心业务关联度不高的通用模块，将其从主要业务代码中分离出来，作为通用代码在需要是被调用，提高代码可重用性；但这里说明的控制器模式更像是一种模块化的编程思想，令不同模块负责不同组件的管理，降低耦合性**

   - 无隐藏API：Kubernetes暴露所有的底层API，具备以自身为底座进行二次建设的能力。Kubernetes支持用户定义新的控制器或CRD，从而加固Kubernetes的底座和扩展Kubernetes的抽象，实现应用功能向基础设施下沉(下沉指将功能放在基础设施实现，通过Sidecar容器将功能加入到Pod中，从而简化应用设计)

     **这个特性比较抽象，个人感觉是运行用户重新建设自己使用的Kubernetes的底座，根据自己的业务需求增添新的功能，从而更适合自己的云原生应用的部署和运行**

   - Kubernetes的专属特性：服务发现和负载均衡、自动调度、存储编排、应用的自恢复、应用版本更新及回滚、配置管理、批处理任务、弹性伸缩

4. Kubernetes运行架构

   Kubernetes的运行架构由Master控制节点和Node计算节点组成，以下分别介绍两种节点的主要部件

   - Master节点：由4个紧密协作的独立组件组合而成，包括etcd、Scheduler、Controller Manager以及API server

     - etcd：用以存储集群中的所有持久化数据和集群状态的分布式存储系统。它除了具备状态存储功能，还有事件监听和订阅、Leader选举的功能。事件监听和订阅，是指各个组件之间的通信不是通过相互之间通过API调用直接进行通信的，而是把状态写入etcd中，由其他组件对etcd中的状态进行监听，以进行后续的处理。Leader选举是指其他组件为了高可用性，通常会有3个副本，由etcd在多个实例中选一个做Master

     - API server： etcd是Kubernetes集群的核心，集群中所有组件之间的通信都需要途径etcd。由于直接让组件监听和访问etcd会使etcd压力太大，现版本的Kubernetes中增加了API server对组件通信进行代理，组件通信通过访问API server进行。API server通过标准的RESTful API，重新封装了对etcd接口的调用，并提供了身份认证、缓存等附加功能。对etcd的访问统一封装在API server中，从而降低了etcd的负载。

     - Scheduler： Scheduler负责资源的调度。在Controller Manager将任务以及任务需求写入etcd后，由Scheduler监听到有新的运行任务(Pod)需要调度，并将其分配到最合适的计算节点上。调度的具体流程为

       从等待执行的Pod队列中取出Pod->通过预选机制选出能够满足资源要求的计算节点->通过评级机制对符合要求的计算节点进行打分，选择最合适的节点->将Pod调度到选中的节点上

     - Controller： 控制器是Kubernetes中进行资源管理的实际组件。由于不同的资源对应着不同的控制器，如Deployment对应Deployment控制器，不同的资源创建请求将由不同的控制器进行控制，并且通过控制器之间的通信进行完整资源创建，如Deployment创建往往对应了Pod的创建。将不同的资源分由不同的控制器进行管理，使得Kubernetes具有更好地成长性，且专业化了各种控制器的功能，通过控制器协作实现整个集群的管理

     - kubectl：命令行工具，用于发出创建请求、写入更新状态、查询更新状态等

   - Node节点：Node节点组件主要包括kubelet和kube-proxy

     - kubelet： kubelet是Node节点的核心组件，主要负责与容器运行时(如Docker)进行协同交互。kubelet与容器运行时的交互是通过调用称为CRI的远程调用接口进行的，该接口调用了容器运行时的各项内容和核心操作。通过CRI的交互使得kubelet并不关心底层的容器运行时是什么，只要容器运行时符合OCI规范，就可以通过实现CRI接入Kubernetes中。容器运行时通过将CRI请求转为对Linux的调用，达到容器创建的目的。

       kubelet还会通过调用网络插件CNI、存储插件CSI，为容器配置网络和持久化存储，以及使用device plugin等插件管理GPU等宿主机物理设备。kubelet创建Pod、更新Pod状态等，都通过监听和访问API Server进行

     - kube-proxy： kuber-proxy是运行在Node节点上的网络代理组件，主要用于实现Service的通信以及负载均衡(kube-proxy核心的功能就是实现Kubernetes的Service功能，即实现集群内客户端Pod访问Service，或者集群外的主机通过NodePort等方法访问Service)。kube-proxy从API Server中获取所有的Server信息，并根据Server信息为Pod创建代理服务，实现从Server到Pod的请求路由和转发，进而实现Kubernetes层级的虚拟转发网络。

       在之前版本的Kubernetes中，kube-proxy默认使用的是iptables模式，通过各个node节点上的iptables规则来实现service的负载均衡，但是随着service数量的增大，iptables模式由于线性查找匹配、全量更新等特点，其性能会显著下降。从Kubernetes的1.8版本开始，kube-proxy引入了IPVS模式，IPVS模式与iptables同样基于Netfilter，但是采用的hash表，因此当service数量达到一定规模时，hash查表的速度优势就会显现出来，从而提高service的服务性能。

5. Kubernetes的API对象

   - Pod： 
   
     Kubernetes中最基础的对象，是一个或多个容器的组合，其中每个容器都负责应用的不同特性操作。Pod中的容器共享一个network namespace，并且可以通过挂载的方式共享同一个存储卷。
   
     Pod是Kubernetes中的原子调度单位，Kubernetes是统一按照Pod而非容器的资源需求进行计算的，Pod为包含的容器进行统一的资源申请，这使得与容器的Linux namespace相关的属性一定是Pod级别的，这样就可以让内部容器尽量共享namespace，形成超紧密关系，降低沟通开销，仅保留必要的隔离和限制能力(Pod中的容器往往是紧密合作的，因此不需要逐个容器划分namespace)
   
     Pod的实现需要一个中间容器，称作Infra容器。Infra容器在Pod创建中永远是第一个被创建的，它的任务是构建Pod的网络，包括设置网络设备、设置设备IP地址和路由信息等。在完成这些任务后，Infra容器将处于暂停状态，不作任何事情，其他容器通过join network namespace的方法加入网络，从而达到共享network namespace的目的。通过这种构建方法构成的Pod网络具有如下特性：
   
     - Pod内的容器可以直接通过localhost进行通信(访问不同端口)
     - 容器看到的网络设备与Infra容器完全一致
     - 一个Pod只有一个IP地址，且其他网络资源也都是一个Pod一份
     - Pod的生命周期只与Infra容器一致，与其他容器无关
   
   - 存储：Kubernetes中的存储(与容器相关的数据存储)分为etcd中存储数据和在volume中存储数据
   
     - etcd-based数据：etcd-based数据主要用于为容器提供预先定义好的配置参数等数据，而Pod中的容器可以通过环境变量或是挂载volume的方式访问etcd-based的数据内容。etcd-based volume并不真实存在，它只是etcd中的一组数据，通过环境变量或是volume的形式为Pod提供数据。etcd的数据对象是以key-value的形式保存的。总体而言，etcd-based数据的核心功能是把配置信息通过API对象保存在etcd中，或是将配置信息以文件的形式挂载在Pod上(volume)，或是将配置信息以环境变量的形式注入Pod容器中。etcd-based数据主要包括以下几类
   
       ConfigMap：用于保存Kubernetes中的配置文件，可以保存单个属性、整个配置文件或者二进制文件
   
       Secret：用于保存Pod想要访问的加密数据，保存的数据通过了Base64转码。Pod中的容器通过挂载volume的方式就可以访问到Secret里保存的信息
   
       Download API：使Pod中的容器能够直接通过API Server，获取到这个Pod API对象的相关信息
   
       ServiceAccountToken： Kubernetes为ServiceAccount自动创建并分配的Secret对象，内容一般为证书或是密码，是用来与API Server进行交互的授权文件。每个Pod都会默认绑定一个ServiceAccount，并为其自动声明一个类型为Secret的volume，然后自动挂载到容器的/var/run/secrets/k8s.io/serviceaccount上。应用程序只要加载该目录下的授权文件，就可以访问并操作Kubernetes的API Server
   
     - volume-based数据：volume分为本地volume和持久化volume，两者具有不同的存储机制
   
       本地volume：本地volume是指在创建Pod时临时创建的volume，其生命周期与Pod绑定。本地volume可能通过hostPath将宿主机的文件系统中某个已存在的目录挂载到Pod上，也可能通过emptyDir在宿主机上创建一个完全随Pod生命周期的临时卷，也可能通过调用Ceph创建存储块并把它挂载到Pod上。(在声明Pod的YAML文件中，volumes声明中采用hostPath、emptyDir将会生成本地volume)
   
       持久化volume(PV)：持久化volume指的是该volume具有持久性，其内容不会因为Pod的删除而被清理，也不会与当前宿主机绑定，容器在任何节点运行都可以通过挂载该volume访问其中的内容。持久化volume的实现往往依赖于一个远程存储服务，其声明主要包含以下几个部分
   
       1. PersistentVolumeClaim(PVC，持久化存储数据卷声明)：PVC用于描述Pod希望使用的持久化数据卷的属性，包括PV的大小、读写权限等。PVC被声明后，Kubernetes将会将其与合适的PV进行绑定，并且在Pod中声明使用该PVC将PV挂载到Pod上。PVC与用户的交互使得用户不需要考虑PV的一些细节内容
       2. PersistentVolume(PV，持久化数据卷)：Kubernetes中持久化volume对应的API对象，定义了一个持久化存储在宿主机上的目录，与PVC一一绑定。静态PV为集群管理员按照使用需求预先创建的PV，可以直接与合适的PVC进行绑定。动态PV指根据PVC中的需求以及相应的模板，在PVC声明时创建的符合对应要求的PV，再将PV与PVC进行绑定。
       3. StorageClass： StorageClass是创建PV的模板，通常里面包含的是用户不关心的必要配置信息，例如提供者、参数、绑定模式、存储插件等。用户通过使用某个PV模板(即StorageClass)，并声明自己所需要的PV的参数(如容量、策略等)，Kubernetes即会利用StorageClass中声明的存储插件根据配置信息动态创建PV，并将其与PVC绑定
   
       **问题：PV具体是如何做到在集群内持久化存储的？PV是在某个宿主机上的目录，如果该宿主机宕机，PV如何继续做到持久化存储**
   
   - ReplicaSet和Deployment：
   
     - Kubernetes ReplicaSet是由Pod副本数的定义和一个Pod模板组成的，负责通过控制器模式保证系统中的Pod的个数永远等于指定的个数。ReplicaSet中只允许设置容器的restartPolicy=Always，要求容器需要能够自启动，否则恢复Pod后容器没有自启动，将导致Pod没有了意义
     - Deployment实现了Pod的水平伸缩以及滚动更新。水平伸缩的实现在于Deployment可以通过操控ReplicaSet对象，修改其控制的ReplicaSet对象中Pod的副本数，从而改变集群中Pod的运行数量；滚动更新的实现在于通过修改Deployment中Pod的模板，Kubernetes中运行的Pod将会交替逐一升级，即旧版本Pod逐渐减少，新版本Pod逐渐增加，最后所有Pod升级完毕。此外，Deployment还会保留历史的ReplicaSet便于进行版本回滚。
   
   - DaemonSet：一个DaemonSet对象能够确保其创建的Pod在集群的每一个(或指定)计算节点上都运行一个副本，如果有新的节点加入，DaemonSet的Pod也会被自动添加到新加入的节点下运行。DaemonSet的删除会级联删除所有的Pod。通常DaemonSet有如下应用场景
   
     - 在每个节点上都运行一个集群存储服务
     - 在每个节点上都运行一个日志收集服务
     - 在每个节点上都运行一个节点监控服务
   
     DaemonSet创建的Pod具有以下的特征
   
     - 集群的每个节点上都会运行一个DaemonSet的Pod
     - 每个节点上只有一个DaemonSet的Pod实例
     - 新加入的节点会自动创捷一个DaemonSet的Pod实例，被删除的节点上的Pod实例也会被相应回收
   
   - Job和CronJob： CronJob用于执行定时处理的任务，在规定的时间周期内运行指定的任务；Job用于批量处理只执行一次的任务，能够确保批处理任务的一个或多个Pod成功地运行和结束
   
   - StatefulSet：用于实现有状态应用，它把应用的状态抽象为三类
   
     - 拓扑状态：应用的多个实例之间不是完全对等的关系，有些应用实例必须按照某种顺序启动。当应用实例被删除后再创建，它们的启动仍然应当按顺序进行
   
     - 网络状态：重启后的Pod的网络标识必须与原来的Pod的网络标识一样，这样才能用原来的方法访问到这个新的Pod
   
       **这里的网络标识具体指什么，IP地址还是其他网络标识？**
   
     - 存储状态：应用的多个实例分别绑定了不同的存储数据，对于Pod而言，其重启前后访问到的数据应当是同一份数据
   
     StatefulSet通过某种方式记录状态，具体采用的方法为
   
     - 拓扑状态：Pod的拓扑状态通过Pod的命名解决，以0、1、2作为Pod名字的后缀，并按顺序逐一创建。StatefulSet中的每个Pod实例名字都携带了唯一且固定的编号，表示了Pod的拓扑关系
   
     - 网络状态：通过Headless Service，直接以DNS记录的方式解析出被代理Pod的地址，然后把该Pod的IP地址注册给"(pod-name).(svc-name).(namespace).svc.cluster.local"(里面的括号表示是Pod名字，Headless Service名字和使用的命名空间)，这样就可以直接通过Pod的域名访问Pod，并可以实时更新Pod中的主机名。即使Pod的IP地址是会改变的，Pod的域名并不会因IP地址改变而变化，因此通过域名访问Pod不受到影响
   
     - 存储状态：StatefulSet使用与Pod相同的命名规则为Pod的每个PVC命名，从而确保Pod与PVC的一一绑定关系。这将使得Pod重新启动后，仍然能够根据其命名规则找到相同编号的PVC，从而找到原来的存储数据的PV。在实际操作中，通常在StatefulSet中声明PVC的模板volumeClaimTemplates，在创建Pod时便会按模板自动创建相应的PVC和PV与Pod一一对应，创建出来的PVC的命名与StatefulSet中的Pod的名字有关。
   
       **这里不理解的话最好在网上看看具体的操作和结果，主要是网络状态和存储状态部分的实现**
   
   - Operator：定义一个有状态应用的实现规范，通过自定义API资源描述想要部署的有状态应用，要求用户按照规范自定义API资源和自定义控制器(通过CRD进行资源定义，通过operator进行控制器定义)，利用自定义的控制器对自定义的资源进行生命周期的监控和管理，从而部署需要满足期望状态的应用
   
   - Service和Ingress：主要作用在于将Pod中的服务提供给外界
   
     - Service： Service对象的主要功能在于为多个服务实例抽象出一个统一的访问接口，并将到达该对象的流量负载均衡到相应的Pod的上进行响应。通过Service对象，可以克服Pod的IP地址的动态性，使其可以被接入，同时为Pod提供了统一的对外入口，使Pod可以为外界提供服务。Service的实现与计算节点上的kube-proxy紧密相关
     - Ingress： Service对象解决了Kubernetes集群内不同Pod之间的通信问题，而Ingress对象主要任务在于将服务暴露到Kubernetes的集群之外，根据自定义的服务访问策略将流量路由给各个Service对象。Ingress的出现解决了nodeport方式暴露服务的弊端(端口难以管理维护的问题)，并使服务能够通过http或https的方式暴露到集群之外(nodeport只支持四层协议通信，不能代理https)。采用Ingress后，Ingress称为外界访问集群服务的统一入口
   
     Service和Ingress的层次结构可以概括为
   
     <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220809212227120.png" alt="image-20220809212227120" style="zoom:50%;" />
   
6. 容器编排的意义：容器编排为PaaS和SaaS提供了自动化封装、打包、部署的能力，实现了应用的生命周期管理，并且还可以用来实现应用依赖服务的维护。容器编排提供的主要功能为

   - 应用编排：帮助构建和管理分布式应用，并为应用构建依赖服务
   - 容器调度：根据调度算法在合适的节点上创建应用
   - 自动伸缩：为了提高稳定性和高可用性，根据应用负载情况增加或减少应用实例
   - 滚动升级：保证在对外服务不中断的情况下升级应用(逐步减少旧版本应用，逐步增加新版本应用)

7. 实现有状态应用和无状态应用

   整个云原生应用可以分为两个部分：无状态部分和有状态部分。业务逻辑往往属于无状态部分，其状态被保存在有状态的中间件中，如缓存、数据库、对象存储等，使得业务逻辑可以很容易地进行横向扩展，且对应用的请求也可以容易地被分发到不同的应用实例上进行处理。后端的中间件保存了状态，其在设计之初就考虑了扩容、状态迁移、复制、同步等机制，不需要业务层关心。而有状态应用会在应用内存储状态信息，如用户登录后要保留会话信息等，这类应用的实例终止，往往会导致会话信息的丢失，导致状态丢失。

   容器以及编排器善于管理的是无状态的应用，可以方便地使用Deployment、DaemonSet等资源类型进行弹性伸缩和滚动更新。无状态应用的下一步就是Serverless的应用。Serverless应用具备"高可扩展性"、"工作流驱动"、"按使用计费"的特点，通过将代码运行或函数调用称为明码标价的对象，不再对运行程序时的资源进行计费，减少了用户进行系统管理的开销。

   由于有状态服务的伸缩非常复杂，因此Kubernetes中采取了计算与存储分离的模式，要求运行在云上的应用尽可能是无状态的，其状态存储迁移到分布式缓存和数据库中，这样可以简化应用的水平伸缩、滚动升级等。Kubernetes首先实现了分布式、无状态应用的部署及生命周期管理。在之后出现的StatefulSet能够满足部分有状态应用的状态表示，而接下来出现的Operator真正实现了分布式、有状态应用的部署以及全生命周期管理。Operator为有状态应用在Kubernetes上的部署提供了一个事实标准，是有状态应用的打包规范。Operator对象不单只是对一个应用的描述，而是对一个完整的分布式、有状态应用集群的描述，要求用户对Operator的定义还应包含管理有状态应用集群的控制器的定义。如何定义实例之间的关系，如何确保实例的状态存储、取用和恢复等问题，都需要通过实现自定义资源的控制器来解决

   **这里书本中讲到了Serverless能够降低用户对系统管理的开销，主要有两个疑问：一是物理机、虚拟机、容器、编排器这些主要的系统管理开销是什么，是镜像版本升级、操作系统管理这些吗？(这个问题个人觉得在真正开始使用Kubernetes等进行应用开发时会更深有体会)；二是Serverless应用具体的改进在什么地方(Serverless应用是怎么实现的)，为什么能够降低系统管理开销？(Serverless还需要进一步进行学习)**

   **有状态应用管理是Kubernetes的一个重要突破，通过采用CRD自定义资源和Operator对象自定义控制器，使得Kubernetes具备了处理有状态应用的能力。但是书本中对CRD和Operator的描述还是相对较少，也难以直接理解Operator的应用，需要进一步了解**

8. 容器编排的最终目标：实现分布式应用的全生命周期管理

   Docker容器实现了应用及其依赖的独立运行，但单单通过Docker无法实现容器的生命周期管理，如容器之间的通信、容器镜像的管理、容器的迁移等。Kubernetes为分布式应用提供了运行环境以及管理应用生命周期的优良工具。通过创建、组合各种API应用，Kubernetes解决了应用状态(etcd存储，API server通信)、存储(本地volume和持久化volume)、动态路由(service和ingress)、弹性伸缩(deployment和daemonset)等问题，使分布式节点上的应用能够有机结合，对外提供高效服务。





## 第二部分：应用架构



#### 第6章 应用架构概述

1. 架构与框架的区分：

   - 架构是针对某种特定目标系统的具有体系性、普遍性的问题而提出的通用的解决方案，是对复杂形态的一种共性的抽象。应用架构从某一个特殊的角度提取相关的重要设计元素，去除不相关元素，以一种最简单、直观的方式呈现应用，让我们能够正确并合理地理解、设计和构建复杂的应用。架构表现出来的就是应用舍去详细实现抽象出来的应用结构，表现为构成的组件和不同组件的关系。架构设计需要考虑应用的各种功能、结构复杂性、性能、技术、所有非功能需要等等，但是忽略具体实现的细节

   - 设计框架是将业务逻辑和完整处理过程分离开，使开发者只需要关注业务逻辑，实现基本的业务逻辑功能，而不需要过多关注实际的处理过程。对于应用而言，其设计框架类似于架构中的逻辑视图，其不关心逻辑部件的具体实现，但是说明了各个部件之间的交互方式。只要模块按照框架的调用"协议"进行设计，即使模块被替换，模块间也能继续协作。这种框架可以理解为应用的总体结构。

     对于应用框架，框架事实上是一个已经开发好的应用，是完整应用的"半成品"，其实现了应用的基本业务逻辑，但是其功能、性能等未能达到生产的需求，需要经过进一步的开发实现具体详细的功能，使其成为"成品"。框架设计的依据在于应用的架构，框架设计为完整应用的构建打下了坚实的基础

   **对于设计框架和应用框架，定义有些区别(这些也是我个人的一些理解和总结，可能有理解不当的地方)。在不同的实际应用场景中，应当对框架进行不同的解释。一篇不错的blog解释了应用架构和应用框架区分：[架构与框架的联系与区别 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/86052051)**

2. 狭义和广义的应用架构

   - 狭义的应用架构：计算机组件以及组件之间的交互，包含了应用根据分工被划分成的不同组件(结构性)、各个组件通过某种机制建立起的关联关系(关联性)、应用建设和延展的边界(约束性)

   - 广义的应用架构：系统完整地分析应用的所有需求，并提出相应的解决方案，旨在给出完整的应用设计方案。广义的应用架构包括应用的整体结构、应用的组件、组件的交互机制、开发组件的技术选型(各个组件的开发方法)、应用的非功能性特性、应用组织的风格(结构复杂性等)

3. 应用架构的定义：应用架构分为业务架构、应用架构和基础架构

   - 业务架构：描述业务的使用者的组织结构(谁来做)、描述外部或内部用户与应用交互的整体流程(交互方法)，描述应用提供的业务能力(做什么)
   - 应用架构：描述应用程序构成及其交互方法，以及它与组织核心业务流程的关系，即定义如何实现应用的业务逻辑功能。应用架构可以细分为以下三类：
     - 功能架构：全面地描述功能模块、规划接口，并基于此明确功能模块之间的使用关系和使用机制
     - 数据架构：描述应用涉及的业务数据及其结构
     - 实现架构：应用组件、模块的具体实现方式和技术选型(这个是个人理解，书本没有详细的解释)
   - 基础架构：描述实现业务、数据和应用程序所需要的软硬件环境
     - 物理架构：描述物理组件及其之间的协作关联(硬件环境)
     - 运行架构：描述应用的运行状态，以及应用在实际物理环境中的实施部署、

   **应用架构定义这一块主要是个人的理解，可能不太准确，在详细的架构学习中期望进一步完善理解**

4. 应用架构的目标：用最少的人力成本来实现构建和维护应用的需求

5. "系统资源"技术的演进对结构的优化

   - 虚拟化技术优化了资源的供给方式
   - 云计算技术自动化和简化了物理架构的部署和配置
   - 容器技术解耦了应用的运行和底层基础设施，并进一步地优化了资源的供给
   - 容器编排实现了应用的自动化部署和生命周期管理



#### 第7章 主流架构

1. "4+1"架构视图：

   由于架构涵盖的内容和决策太多，需要采用分而治之的方法。一个架构的视图指的是从某一视角或某一点出发对系统做简化描述，描述涵盖了系统的某一特定方面，而忽略了与此方面无关的实体。由于不同涉众对架构的理解存在较大差异，不同的涉众需要从应用架构的不同角度参与架构决策(即通过不同视图进行交流)，独立分析和设计不同的子问题，从而简化和清晰化架构设计。

   **这里解释了采用不同架构视图进行架构设计的原因：涉众的理解和看待问题的角度的差异、应用架构全面性导致需要采用分而治之的方法**

   "4+1"视图主要为以下几点

   - 逻辑视图：逻辑视图规定了应用由哪些逻辑组件组成，以及这些逻辑组件之间的关系。这些逻辑组件可以是逻辑层、功能子系统、模块。从面向对象设计来看，可以用对象模型代替逻辑视图，将架构的各个功能模块分离并封装成类，然后将对象类和功能类之间的所有关系表示出来。

     <img src="https://pic4.zhimg.com/v2-2eadc5c4c31a5e45c6fc7b616288aa5f_r.jpg" alt="preview" style="zoom: 33%;" />

   - 开发视图：开发视图也被称为模块视图，主要侧重于应用开发过程中的工程模块的组织和管理(开发环境中软件的静态组织结构，包括文件组织结构、程序包、编译依赖关系等)。开发视图主要考虑应用内部的需求，如应用开发的容易性、应用模块的重用等，要充分考虑由于具体开发工具的不同带来的局限性。开发视图通过系统输入/输出关系模型图和子系统图来描述

     开发视图通常采用层次结构风格，每层仅能与同层或更低层的子系统通信，这使得每层的接口既完备又精炼，且各个模块之间避免了复杂的依赖关系。层次越低的模块，通用性越强。

     开发视图的涉众是程序员，其标准在于：通过逻辑架构元素，能够找到它所有代码和所有的二进制交付件；每一个代码源文件，都能够找到它所属的逻辑架构元素；每一个二进制交付件，都能够找到它集成了哪些逻辑架构元素(这个要求想说明的是开发视图完整地将逻辑视图映射到软件文件组织上)

     **根据描述，个人认为以下是一个较好的开发视图的设计，助于理解(包含了子系统图和输入输出关系)。这个图可能也不够准确，但是网络上缺乏一些实例，不好理解。感觉真正完整的开发视图包含了系统完整的文件组织结构和程序包组织等，但是这样的话体现不出对应用内部需求等的考虑，因此可能开发视图也不需要设计的这么详细，主要通过规划子系统和层次结构，确定输入输出关系，并考虑开发工具和模块重用等即可。**

     <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220811131128062.png" alt="image-20220811131128062" style="zoom:50%;" />

   - 进程视图：进程视图侧重于应用的运行特性，主要关注一些非功能性需求，强调系统并发性、分布性、系统集成性和容错能力等。进程视图描述了逻辑视图中的主要抽象功能是如何适应进程结构的，以及逻辑视图中各个逻辑组件的操作具体是在哪一个线程中进行执行。(从线程、进程的角度描述逻辑视图中功能抽象和功能组件的实现，说明了不同线程、进程代表的模块以及负责的任务，展示了逻辑视图中的具体工作流程。进程视图类似于UML中的时序图，但是将任务映射为了线程和进程)

     <img src="https://images0.cnblogs.com/blog/534617/201306/30134348-693b37c58caf4341bf72bb6147dd2cef.png" alt="img" style="zoom:50%;" />

   - 物理视图：物理视图主要考虑把应用程序映射到具体的物理硬件上，描述了组成应用的物理元素、这些物理元素之间的关系，以及将应用功能部署到硬件上的策略。物理视图就是分配应用组件的物理资源，将组件或进程的物理资源的分配情况具体展示出来。物理视图类似于UML中的部署图，将功能部件映射到具体的硬件资源上

     <img src="https://images0.cnblogs.com/blog/534617/201306/30134929-ac3afc0859974a2998181e3e138ab5d1.png" alt="img" style="zoom: 50%;" />

   - 场景视图：场景视图是"4+1"视图中的最后抽象，将其它4种视图有机地联系起来，从某种意义上看是最重要的需求抽象。在开发应用时，场景可以帮助开发者找到应用框架的组件以及它们之间的作用关系。同时，也可以通过场景来分析一个特定的视图或者描述不同视图组件间是如何相互作用的。场景视图就是通过一个现实中的应用运行过程，展示其中设计的对象、服务和操作。(场景视图可以通过逻辑视图中增加一些箭头表示调用等进行表示，说明了在某种场景下模块间的交互关系，相当于UML的用例图，说明用户通过哪个模块可以实现哪些功能)

     <img src="https://gss0.baidu.com/9fo3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/9825bc315c6034a87472ff84cb13495409237626.jpg" alt="查看源图像" style="zoom:50%;" />

   "4+1"视图是描述应用架构的一种方法，它通过采用多种视图描述某一业务场景下应用的协作和运行，进而串联整个应用的不同成分元素。但是从应用的整体角度来看，"4+1"视图不够全面，无法完整地描述应用的不同架构方面，只用它来进行架构设计(应用建模)是不全面的

2. ArchiMate：一套被广泛认可的架构描述建模语言。ArchiMate使用清晰的概念和关系来描述架构领域，提供了简单一致的结构化架构描述模型。ArchiMate从业务架构、应用架构和技术架构三个层面来完整描述一个应用

   - 业务架构：业务架构提供对用户业务服务的描述，这些服务由业务角色通过业务流程来实现(用户能获取什么业务服务、如何获取业务服务)
   - 应用架构：应用架构是用于支撑业务活动的应用组件，用于实现应用的主题业务逻辑(某个业务功能需要哪些应用支撑)
   - 技术架构：技术架构通过软件和硬件来支持应用程序的运行(应用组件需要哪些技术支撑)

   三个架构都使用了主体、行为、对象三个方面进行建模

   - 主体：主体元素可以通过不同形式的主体接口方法调用行为服务
   - 行为：行为由一个或多个行为元素实现，对外暴露为具有某项功能的服务
   - 对象：通过行为元素可以创建、使用、修改所涉及的对象

   将上述三个层面与三个方面相结合，先分层，再根据不同的方面分成不同的领域，将企业应用划分为如下结构

   <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220811172133071.png" alt="image-20220811172133071" style="zoom:50%;" />

   业务层、应用层和技术层的主要成分划分为(根据最终的图来一一理解)：

   - 业务层：

     业务层主体是组织架构域，其具体可以包括以下几种角色

     - 业务参与者：业务参与者是执行某些行为的一个组织实体，通过一个或多个业务角色来执行行为
     - 业务角色：业务角色是执行一组特定行为的角色。业务角色根据职责和技能来执行或使用业务流程和业务功能
     - 业务接口：业务结构是业务服务对外暴露的方式，是业务角色使用业务服务的方法

     业务层的主要行为由流程领域来体现

     - 业务流程：包含更多业务子流程或业务功能的一个工作流，角色使用某项业务服务需要完成一个业务流程，即业务流程实现了业务服务
     - 业务功能：提供一个或多个对业务流程有用的功能
     - 业务事件：触发业务流程的事件
     - 业务服务：外部可见的功能单元，业务角色调用业务接口使用业务服务，业务服务形成某个业务事件触发业务流程。

     业务对象是业务层操控的信息，由业务流程、业务功能、业务事件、业务服务进行使用

     **问题：业务功能体现在哪里？业务功能是业务流程提供的功能，还是为业务流程提供功能**

   - 应用层：

     应用层的主体和行为都集成在应用域，其主要成分为

     - 应用组件：应用组件是一个独立的功能单元，它实现了一个或多个应用功能。应用组件通过应用接口进行访问，外部组件通过接口使用应用组件实现的功能
     - 应用接口：应用接口规定了外部组件应当如何使用当前功能组件，包括输入参数、数据格式等，并对外输出当前功能组件执行完毕后生成的输出结果。对于应用组件而言，应用接口为供接口，要求外部组件通过某种方式访问应用组件；对于外部组件而言，应用接口为需接口，表示应用组件为外部组件提供了什么功能
     - 应用服务：应用服务由一个或多个应用功能实现，通过定义良好的接口为外部提供可见的功能，实现与业务层的对接。应用服务可以被业务流程、业务功能或应用功能使用。应用层对外表现为不同的应用服务，应用服务通过调用应用接口使用应用组件提供应用功能
     - 应用功能：应用功能描述应用组件内部的行为，可以用于实现应用服务或使用其他应用功能提供的应用服务。外部只能通过应用服务使用应用功能。

     应用层的对象是数据对象，用于进行组件的信息传递和交互等

     **问题：应用服务对外也是通过暴露接口的方式提供服务，那么应用接口是单指应用组件的接口，还是包含了应用服务的接口**

   - 技术层：

     技术层完全由技术架构域表示，它包含了以下几个部分

     - 工件：工件代表事实存在的具体展现元素，如元文件、可执行程序、脚本、文档等。工件被部署在一个节点上，一个应用组件可以由一个或多个工件实现
     - 节点：节点是执行和处理工件的元素，如服务器、虚拟机、应用服务器等。节点能通过通信路径进行连接
     - 设备：设备是节点的继承元素，代表具有处理能力的物理资源，通常用来对硬件建模，如主机、PC或者路由器
     - 网络：网络用于连接两个或多个设备，令设备间能够进行交互通信，有带宽和响应时间等属性
     - 基础设施服务：基础设施服务由一个或多个节点组成，通过定义好的接口对外提供可见的功能单元。外部环境通过基础设施接口访问基础设施，获取某种的服务，如消息服务、存储服务、域名服务等
     - 基础设施接口：基础设施接口指定了某种基础设施服务如何被外部访问
     - 系统软件：如操作系统、数据库系统、应用服务器等

     **按照平时的观点，设备与节点似乎是不同的部分，为什么说设备是节点的继承元素**

   <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220811173903518.png" alt="image-20220811173903518" style="zoom:50%;" />

3. TOGAF框架：结合ArchiMate模型语言描述业务、应用和技术的不同层面，从而实现一套完整的企业应用体系。应用采用不同的视图或架构来呈现其不同方面的特性，而架构框架主要用于如何组织和使用这些视图或架构，理清不同视图之间的关系，实现标准化的流程和高质量的应用软件交付。架构框架事实上就是一种架构的设计模式，说明了标准架构的组成成分以及成分之间的联系，作为不同应用架构开发的规范，可被用于应用架构开发的不同阶段。TOGAF及ADM(架构开发方法)详细描述了如何定义业务架构、数据架构、应用架构和技术架构，它们是描述企业级应用架构的最佳实践指引

   TOFAG是一个架构框架，其同时也是一种协助开发、运行、使用、验收和维护架构的工具。其具体内容为

   <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220811210009106.png" alt="image-20220811210009106" style="zoom: 33%;" />

   ADM(架构开发方法)为开发企业架构所要执行的各个步骤以及它们之间的关系进行了详细的定义，同时它也是TOGAF规范中最核心的内容。ADM是企业应用顺利演进的规范和保障，而企业架构资源库为架构开发的执行过程提供了各种可重用的信息资源和参考资料，且ADM中各步骤所产生的交付物和制品也会不停地填充和更新企业架构资源库。通过对ADM的循环迭代，资源库中的内容将会日趋丰富和成熟，使得企业架构的开发也会越发简单和快捷。ADM的迭代过程可总结为

   <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220811212000936.png" alt="image-20220811212000936" style="zoom:50%;" />

   **具体的迭代步骤太多而且繁琐，这里只对ADM和TOGAF做个简单的介绍，具体过程详见书本P112**



#### 第10章 微服务架构

1. 微服务架构简介：微服务架构是分布式SOA的一种延伸，以一系列服务的方式将应用组织起来。微服务架构模式将应用分解为一组粒度更细的微服务，每个微服务都由一组专注的、内聚的功能职责组成。它将微服务作为模块化单元，通过微服务的API构建起对外无可逾越的边界，使外部无法越过API访问应用内部资源。微服务内部的变更不会触发其它微服务的更新，实现了真正的松耦合。

2. 微服务架构设计对应用的影响

   - 从应用运行的角度来看，云为应用提供了强有力的支撑。通过部署应用时动态插入Sidecar(与应用容器运行在同一个Pod的容器，用于对接云平台)，对接云平台提供的基础设施和中间件产品，实现服务发现、负载均衡、路由、加密、熔断、限流及日志监控等各种底层非业务功能，极大地减轻了应用的负担，强化了应用的能力
   - 从应用开发的视角来看，云原生应用仅需完成业务逻辑开发，然后采用标准化的部署方式让应用上云，即可享受云计算的便利

   **问题：这里提及的影响，主要说的是云原生模式开发的应用具有的优势，是否说明云原生应用采用的架构是微服务架构，在一个Pod中，多项微服务以容器的形式运行在Pod中，以API网关的方式对外暴露。每项微服务在同个Pod中都能享受到Sidecar容器带来的功能**

3. 微服务架构与SOA：这个希望在阅读完SOA模式后，再来阅读进行理解

4. 微服务架构与容器编排

   微服务架构将应用解耦拆分成了细粒度的服务模块，而与之配套使用的容器技术，采用细粒度的管理模式为微服务提供了更有效的资源供给和管理，轻量化帮助微服务进行快速启动和伸缩。每个容器中都封装一个微服务的技术栈，并实现了与运行平台的解耦，使容器是微服务的最佳载体

   容器编排器Kubernetes原生集成了许多微服务治理的功能，而如Istio等服务网格技术弥补了Kubernetes所不具备但微服务治理所需的其他功能。Kubernetes+Istio实现了一套完整的微服务治理功能

5. 采用微服务架构的优势与难点

   优势方面

   - 敏捷性：微服务架构有助于更加敏捷地实现发布、更新和部署。以微服务为单位进行更新等操作，降低了修改的风险和管理复杂性，让升级粒度更细、发布变更的影响更小，使大型的复杂应用可以持续交付和持续部署
   - 自治性：每个微服务都可以独立开发，具有异构型，可以由不同的开发团队采用最合适的技术栈来实现。微服务架构使开发团队专注于应用的一个小的方面，从而提升生产效率和微服务质量
   - 伸缩性：微服务通过容器技术可以快速地进行水平扩展，并通过云平台上的其他组件进行伸缩和负载均衡
   - 隔离性：每个微服务都运行在独立的运行环境下，使单个微服务的出错不会影响到其他微服务，导致应用发生灾难性故障。隔离性使得微服务的耦合度更低、灵活性更强，运维和管理成本更低

   技术难点上

   - 应用拆分：对应用进行微服务的拆分，必须明确服务之间的依赖关系(确保各个服务是独立的个体，一个服务的构建可能引发其他多个服务的构建)
   - 测试诊断：由于整个应用在微服务架构下采用分布式的模式，微服务之间通过通信的方式进行联系，这使得整个应用的开发、测试和部署变得困难，特别是对微服务的协同性进行测试
   - 部署运维：应用拆分成多个微服务，导致会出现海量微服务的情况，需要有自动化的运维方式
   - 稳定性：采用微服务的应用内部具有非常多的微服务之间的调用(微服务间的调用往往是通过网络进行的，因为每个微服务属于不同的个体，通过API网关进行访问)，使得网络延迟或抖动会造成应用的不稳定
   - 事务一致性：采用微服务架构，使得有逻辑关系的多个数据库操作可能会被打散到不同微服务中。而微服务的分布式调度和运行将导致分布式环境下的事务一致性问题。这往往需要采用额外的分布式事务框架来解决微服务之间的数据一致性问题
   - 落地门槛高：团队架构改变和技术提升很难一步到位，容易出现长时间内投入与收入不成正比的情况(改革难度大)

6. 微服务机构详解：功能架构、技术架构和部署单元

   - 功能架构：业务领域建模是微服务应用功能架构的核心，每个微服务都围绕业务领域概念来定义，并将实现架构以及其所依赖的其他组件封装在该微服务中，实现高度解耦。每个微服务都包含了所有的元素，并通过REST等协议与其他微服务进行通信。

   - 实现架构：应用的实现架构有整洁架构、六边形架构和分层架构三种。虽然这三种架构的展现方式以及解决问题的出发点不一样，但其架构思想与微服务架构高内聚、低耦合的设计原则高度一致。

     **实现架构的进一步知识还难以了解，需要进一步学习**

   - 部署单元：部署单元的大小在很大程度上决定了应用的耦合性和灵活性。微服务架构中，每个微服务都是一个部署单元，可以实现独立部署，确保在更新一个微服务时不会影响其他微服务，从而实现其演进式的架构目的。应用的每个微服务都是按照业务领域来拆分的，每个微服务都包含了全技术栈服务和封装了完整的实现架构，独立进行开发、部署，实现无共享架构。

     **问题：怎么称为一个业务领域，如何按照业务领域划分**

7. 设计原则：每个微服务通过统一的API网关对外提供服务，各个微服务之间通过REST或gRPC协议通信。微服务可以通过调用多个不同的微服务来实现自己的功能，同时每个微服务都要有自己独立的数据存储。微服务的部署、运维等需要通过自动化的手段实现

   - 服务注册中心：微服务架构需要通过一个服务注册中心来管理微服务的实例。每个服务实例启动时，向服务注册中心注册自己的IP地址、服务类型等信息，使得其他服务要调用该服务时，可以通过服务注册中心查询到该服务的实例的访问方法

   - API网关：API网关是访问微服务应用的统一入口。API网关为微服务应用的所有微服务提供了一个统一的接口，避免用户访问不同服务需要发出多个请求的情况，降低了响应时间。另外，如果让外部服务直接访问微服务，当微服务开发人员在迭代过程中更新、修改微服务的API时，会影响到调用者。有些微服务会提供gRPC或AMQP等非REST协议，可能会无法穿透防火墙，因此需要API网关统一封装对外公开的API

     API网关作为从防火墙外部进入应用的API请求的单一入口，负责请求路由、登录认证和协议转换。外部请求首先到达API网关，API网关可能直接转发到相应的微服务上，也可能根据请求调用多个服务并聚合结果。API网关还可以进行协议转换，使微服务的API能采用合适的协议，而不需要考虑被客户端调用的情况。

     API网关的功能包括：路由、负载均衡、统一认证和鉴权、监控、日志、限流降级等。API网关的所有扩展都基于插件来实现，与插件形成多对多的关系(API网关可以使用多个插件、一个插件可以被应用在多个API网关)。API网关的缺陷在于请求增加了一跳，对性能有影响，且API网关增加了部署和运维的复杂度。

   - 跨服务通信：

     - 同步REST：主流的微服务采用REST风格来开发API。REST使用HTTP动词来操作资源，使用URL来引用这些资源。REST的缺点在于REST只支持同步请求/响应方式、单个请求中无法获取多个资源、无法将复杂的操作映射在HTTP动词上
     - 同步gRPC：gRPC是一个用于编写跨语言客户端和服务端的框架，它使用基于Protocol Buffer的IDL定义API，是可以序列化结构化数据的一种中立机制。gRPC的优点在于 即使API本身功能较为复杂，使用gRPC也不会太过复杂；gRPC能支持大规模的消息交换
     - 异步消息队列：微服务架构中若采用同步通信机制，客户端必须等待服务端返回响应，导致影响应用的可用性，因此采用异步消息队列来实现服务间的通信。异步消息队列是松耦合的，客户端在发送请求时只需要发送到消息队列，不需要知道服务实例的情况。且消息代理可以缓存消息，等待服务端在线后进行消息处理。但是异步消息队列也存在诸如性能瓶颈、单点故障等潜在问题

   - API设计：由于数据库可能分布在不同的微服务中，导致了接口设计和编写变得复杂

     - API组合模式：客户端调用拥有数据的多个微服务，并将服务返回的结果进行组合。实际操作过程中，通常会设计一个单独的API组合服务，对内调用多个微服务，对外提供标准的REST查询接口。API组合服务可以通过并行调用微服务，缩短响应时间。API组合模式存在性能开销大(需要调用多个微服务和查询多个数据库)、可用性下降(需要与多个微服务进行连接，可用性随微服务数量增加而下降)、数据一致性难以保证等问题

     - CQRS模式(查询修改分离模式)：通过分离查询操作和修改操作，使得跨微服务的查询更加高效。CQRS设计模式通过维护一个或多个只读视图数据库，从不同微服务数据库中复制出只读视图，借此实现对多个微服务的数据查询。通过采用一个类似API组合模式中的API组合服务，在这个服务上维护一个只读视图数据库，通过订阅相关领域事件的方式与源数据库同步。在采用查询指令时，可以直接在视图数据库上查询内容。采用修改指令时，组合服务通过调用微服务，实现修改。

       **关于CQRS模式的问题：CQRS模式究竟是应用在单个微服务的API设计上，还是应用在多个微服务的API设计上，是API组合模式的升级。如果是应用在单个微服务的API设计上，只需要源数据库即可，为什么还要增加视图数据库(可能视图数据库中不使用关系数据库，直接组合了多个表，加快了查询效率，在读大于写的应用中非常有效，且独立的读模型可以简化读操作)，且视图数据库如何整合不同微服务的数据(这个是最主要的疑问)；如果是在多个微服务的API设计上，是否需要一个统一的服务进行视图数据库的维护**

       **我个人的推测是这里采用CQRS模式是指对多个微服务采用CQRS模式，书本P171；CQRS模式应用在单体应用上更容易理解**

       **[什么是 CQRS？它在微服务中有多重要？ (jdon.com)](https://www.jdon.com/61877#:~:text=CQRS 是一种微服务,架构模式 ，它代表命令和查询责任分离。)**

     **问题：这里提到的API设计与API网关有什么区别？它们之间有调用关系吗？与API的具体设计有什么关联(更像是分布式数据库查询的解决方案)**

   - 数据一致性原理：分布式系统中的重要问题

     - ACID强一致性模型：单体应用采用单一数据库模式，可以通过遵循ACID理论，保证应用数据的一致性，通常采用关系数据库实现

     - CAP原理：由于微服务架构下，事务往往需要跨过多个微服务数据库，需要更新多个数据库拥有的数据，这使得传统的事务处理以及无法满足要求，需要更为高级的事务管理机制

       分布式系统需要达到的CAP原理(不可能同时做到)为：

       一致性C：对于分布式系统分布在不同节点上的数据，如果某个节点上更新了数据，其他节点上能够访问到同一份最新的数据，则称分布式系统具有一致性(读取到的数据的一致性)

       可用性A：非故障节点应在合理的时间(不能无限期阻塞)内返回合理的响应，而不是返回错误和超时的响应。高可用性指任何一个节点一旦接收到用户的请求就必须作出回应，不允许有时间上的延迟

       分区容错性P：在分布式系统中，每一个独立子网络都是一个分区，当某个分区的网络出现抖动或问题时，系统整体仍旧能够继续工作，则称这个分布式系统具有分区容器性

     - BASE原理：BASE是Basically Available、Soft state和Eventually consistent的缩写，其核心理念为

       基本可用：分布式系统出现故障时，允许损失部分可用功能，保证核心功能可用

       软状态：允许系统中存在中间状态，损失部分一致性

       最终一致性：经过一段时间后，所有节点数据都将达到一致

   - 分布式事务处理：维护不同节点数据的一致性，确保事务在不同微服务上的操作要么都成功，要么都失败

     - 2PC分布式事务：采用两阶段提交来保证事务中的所有参与者要么同时提交，要么在提交失败时同时回滚。两阶段主要行为为

       第一阶段：请求/表决阶段。事务发起者向分布式事务协调者发送事务执行请求，由事务协调者向所有参与事务的节点发送预处理请求。参与者节点在尝试处理事务后，先不提交本地事务，而是根据事务执行情况向分布式事务协调者反馈事务是否能够执行完成

       第二阶段：提交/执行阶段。分布式事务协调者得到所有参与者节点的反馈。如果所有参与者节点都能够执行事务，则通知所有参与者节点提交事务，否则通知所有参与者回滚本地事务，释放资源。参与者完成操作后，向协调者回复ACK消息，由协调者向调用方返回事务处理结果

       2PC分布式事务存在单点问题，不支持高并发

     - TCC分布式事务：TCC分布式事务分为三个操作执行

       Try：业务应用通知参与者服务尝试执行事务，完成所有业务检查(可行性检查)，预留必需资源；当所有参与者服务能够执行事务时，业务应用通知分布式事务协调服务调用Confirm接口，否则调用Cancel接口

       Confirm：使用预留的资源直接执行业务，不做任何业务检查。Confirm操作满足幂等性，因为Confirm操作失败后需要进行重试

       Cancel：取消执行，释放Try阶段预留的资源。Cancel阶段与Confirm阶段异常处理方案基本一致

       TCC适用于有强隔离性、严格一致性要求的活动事务，事务执行时间较短。通常通过消息日志的方式来异步执行

       <img src="C:\Users\pentakill\AppData\Roaming\Typora\typora-user-images\image-20220813214610771.png" alt="image-20220813214610771" style="zoom:50%;" />

     - 本地消息表：通过在每个服务上维护一个本地消息表。当某个服务需要维护事务时，先检查自身操作的可行性，若可行，则将事务放在本地消息表中。集群中由一个定时任务轮询本地消息表，并将本地消息表中没有发送的消息发送到参与者服务。参与者服务将事务操作的完成情况放到本地的消息表上，等待定时任务轮询并转发给事务发起者。事务发起者根据所有参与者的操作完成情况选择提交或回滚，并最后通过消息表通知所有参与者进行提交或回滚

     - MQ分布式事务：在Message Queue消息队列中实现分布式事务，事实上就是对本地消息表进行封装，并将本地消息表移动到集中的消息队列中。

     - Saga：由Saga事务协调器对常规事务和补偿事务(常规事务的反操作)进行排序，协调器通过持续异步调用事务参与者，执行常规事务，完成所有常规事务后协调器进行事务的提交。如果任何一次操作失败，则协调器通过相反顺序通知事务参与者执行补偿事务，完成回滚。事务操作缺乏隔离性



#### 第11章 微服务框架

1. 微服务架构的问题：应用的从单体架构变成了由多个微服务组成的微服务架构，而每一个微服务有多个实例分布在分布式集群上，因此配置、部署、扩展和监控工作变得非常复杂，而且还需要服务发现机制来发现与各个微服务实例通信的地址。微服务架构的应用的部署应有足够的部署控制方法，并实现高度自动化的部署和运维。

2. 微服务框架核心功能

   - 服务注册发现：微服务的注册发现是指应用的客户端与服务端的服务注册表进行交互，整个交互过程分为服务端的自注册和客户端的发现两个步骤。服务端的自注册是指服务实例向服务注册表注册，即服务可能存在多个实例，每个实例都需要向注册表说明自己的IP地址和端口等通信方式；客户端的发现是指客户端服务从服务注册表中检索可以使用的服务端服务实例，并在他们之间进行负载均衡。服务注册表还会定期调用服务API提供的"运行状态检测"端点，验证服务实例是否可用(可用性检查)

     服务注册发现的另一个可行手段是：客户端实例向DNS和VIP发送请求，由平台将请求解析到路由器，并通过查询服务注册表对请求进行负载均衡。这使得服务端和客户端都不需要集成服务发现代码，有更强的通用性

   - 服务负载路由：微服务架构下的应用将自身拆分成了多个后端服务，为了简化请求的复杂性，需要一个统一的入口，将不同的请求路由到不同的后端服务，这样前端不需要了解后端服务的地址等，能够应对变化IP的情况。微服务架构通过引入API网关，将数据聚合、请求路由、认证和鉴权等操作统一封装在了API网关上进行，这简化了外部对服务的调用，且令内部服务不需要再封装认证和鉴权的代码，降低了复杂度且提升了效率。API网关往往是无状态的，可以进行横向扩展，不会出现单点故障和性能瓶颈的问题

   - 统一配置：由于微服务数量众多，如果将微服务的配置都以配置文件的形式存放在应用中，将会增加巨额的管理开销(修改需要逐一修改配置文件并应用修改、出现问题难以找到错误)。因此，通过使用一个统一的配置中心，管理所有的配置，进行统一的配置下发这使得配置项发生修改时，配置中心会通知服务告诉各个微服务实例配置项的变更状态，由微服务实例使用新的配置项，实现应用的动态更新

     配置文件的发放有两种方案：配置中心push给各个服务(可能因网络抖动造成消息丢失)、服务从配置中心pull配置文件(实时性较差)

   - 服务编排与弹性伸缩：通过使用编排器和编排文件，实现微服务的发布、更新、回滚、扩容等操作，增加服务的可追溯性、易管理性和自动化的能力。这点可以通过将微服务架构的应用运行在Kubernetes的容器上进行应用的编排实现。编排一般分为资源编排(物理资源的定义与分配)和服务编排(应用服务的弹性伸缩、滚动升级、资源配置等)

   - 流量管控：微服务中的流量管控主要包括

     - 断融：一个远程微服务调用在连续失败次数超过指定的阈值后的一段时间内会拒绝其他调用，快速返回错误信息(负载过高、微服务出现故障、恶意调用)。当一个微服务发现被调用的微服务因过于繁忙、线程池满等问题而多次调用超时或失败时，应即使熔断，防止因被调用服务错误导致本服务不正常。(两种情况，断融指被调用服务自身总是出错时拒绝其他服务的调用，熔断是调用服务主动断开调用)
     - 限流：根据全链路的压力测试结果，了解全应用的支撑能力，制订相应的限流策略，保证应用处理请求处于其支撑能力范围内，拒绝超出其支撑能力范围的请求处理
     - 降级：当整个应用服务负载过高时，通过降级某些功能来保证核心交易流程正常工作，将最重要的资源用于保证最核心的流程(调整资源分配，延迟或暂停非核心应用，确保核心业务)

   - 可观察运维
     - 健康检查：定时调用服务提供的健康检查API，检查服务实例的可用性
     - 统一日志聚合：微服务实例将日志发送给集中式日志服务器，在支持搜索的集中式数据库中聚合所有的微服务日志，避免日志过度分散。
     - 监控告警：监控系统从技术栈的每个部分收集有关应用程序健康状况的指标，将指标数据发送给负责聚合、可视化和告警的中央监控服务。主流监控系统采用Pull模型，监控服务调用各个微服务的监控API，从微服务实例检索指标信息
     - 全链路追踪：把一个请求从进入微服务应用到返回过程中的相关数据，包括函数性能、错误日志、异常堆栈等数据联合起来，形成一个诊断闭环。全链路追踪通过使用一个固定值标记请求经过的整条链路(在请求调用微服务时不断传递这个固定值)，从而可以通过这个固定值获取链路的行为日志，并对此进行分析和诊断

3. 框架分类

   - 业务处理框架：在应用业务逻辑代码中封装负载均衡、服务发现、分布式追踪等技术，使得应用具有处理网络弹性逻辑的能力(这里的应用应该指的是微服务框架中的微服务，即让每个微服务都可以进行负载均衡、服务发现等)。这种框架缺点明显，如耦合度高、资源利用率低下(没有共享模块)、可运维性差(组件封装在微服务中，不能独立存在)、灵活性差(某一项逻辑改变需要整个应用的变化)等

   - SDK框架：将业务逻辑中封装在应用的服务发现、负载均衡、分布式追踪、安全通信等微服务治理功能独立为一个公用库。SDK框架使得应用与微服务治理功能有更低的耦合性，而且这种模式更加灵活，提高了共性功能的利用率以及可运维性。开发人员只需要使用公用库即可，降低了负担且提升了应用质量

     SDK框架实现通常需要一个集群化的分布式配置中心来充当服务注册的存储器，存储服务端的服务注册表或是注册服务的调用方法。服务框架分为客户端和服务端，客户端提供服务的发现、软负载、路由、安全、策略控制等功能，服务端实现服务调用。

     SDK框架在耦合性、灵活性、利用率等方面有很大的提升，但是缺乏多语言的支持(不支持异构环境开发)、可运维性(代码库的修改会影响整个应用)仍然不足。且开发人员为了使用好公用代码库，需要昂贵的学习成本，学习公用库的使用方法

   - 服务网格：服务网格可以视为解决应用服务间通信的基础设施层，负责为现代云原生应用程序的复杂网络服务拓扑提供可靠的信息传递。服务网格的核心是网络代理，通常通过一组与应用部署在一起的轻量级网络代理来实现(Sidecar模式)，即负责微服务治理功能等的组件插入到与微服务部署在一起的服务代理中，为微服务应用提供服务发现、负载均衡、动态路由、容错限流、监控度量和安全日志等功能

     简单来说，可以将服务网格代理比作现实生活的中介，它通过在需要通信的两个服务之间增加一道关卡，为服务通信提供消息拦截、流量统计、消息缓存等功能。服务网格把微服务的治理工作统一在了代理层实现，通过统一的控制平面，管理员只需要做部分配置，即可由服务代理自动化管理应用。在Istio中，每个应用的Pod中都运行一个代理Envoy，负责与流量相关的治理，从而治理微服务。

     服务网格从平台层面为微服务提供了热更新、注入服务发现、降级熔断等功能，为基于微服务架构的应用做了定制化的改进。为每个微服务配置合适的服务网格(即网络代理，能够支持异构应用)，实施微服务治理以及其他功能，使得应用完全与微服务治理功能解耦，只需要关心自己的业务逻辑

     服务网格具体实现与前面的应用架构有关，还没能完全理解其中的意思，需要进一步学习



## 第四部分 架构、应用落地与中台构建



#### 第17章 云原生架构

1. 云原生的意义：使应用开发人员能够敏捷地以可扩展、可复制的方式，最大化利用云平台的能力，发挥"云"的价值，避免开发人员构建不可扩展的应用，进而避免了资源浪费和效率低下

2. 云原生应用的特性：12因子应用

   - 基准代码：一个应用服务只有一份基准代码，可以根据不同配置部署到不同环境中
   - 依赖：应用的所有依赖关系(编译和运行时)需要被显式声明
   - 配置：在环境中存储配置，而不是在代码中存储配置   **问：什么是在环境中存储配置，采用环境变量？**
   - 后端服务：后端服务作为附加资源，不加入基准代码中，使应用专注于业务逻辑
   - 构建、发布、运行：严格分离构建和运行，分别制作编译的镜像和运行的镜像，即避免直接将源代码加入运行镜像中，而是将可执行文件放入运行镜像
   - 进程：以一个或多个**无状态**进程运行应用
   - 端口绑定：通过绑定端口对外提供服务或进行服务间通信
   - 并发：可以并发对外提供服务
   - 易处理：预先确定启动和终止的理想机制，保障应用的数据完整性 **问：如何称为启动和终止的理想机制，启动和终止的状态？**
   - 环境等价：保持开发环境、预发布环境和线上环境相同(采用容器和相同配置文件)
   - 日志：把日志作为事件流来处理
   - 管理进程：后台管理任务通过Sidecar模式启动另一个进程运行

3. 云原生架构的特征：模块化、可观测性、可部署性、可测试性、可处理性、可替换性

   云原生的构成：微服务、容器、开发运维一体化(DevOps，开发运维工作紧密结合)、持续交付

   **开发运维一体化、持续交付等概念还需要进一步学习了解**

4. CNCF对云原生的定义

   - 应用容器化：容器技术让应用有了一种完全自包含的定义方式，从而使应用能够以一种敏捷的可扩展、可复制的方式部署到云上
   - 动态编排调度：由中心化的编排来进行活跃的调度和频繁的管理，从根本上提高机器效率和资源利用率
   - 面向微服务：应用被拆分成微服务，从而显著提高应用的整体灵活性和可维护性

   CNCF对云原生技术意义的总结：云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。利用云原生的容器、微服务、服务网格、不可变基础设施、声明式API等技术，能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统做出频繁和可预测的重大变更

5. 本书对云原生的定义

   云原生的核心思想：将应用的非业务逻辑下沉到基础设施中，成为云平台的一部分，在不被应用感知的情况下为应用赋能。云原生主张加强和改善应用运行环境来帮助应用，让应用轻量化成为可能

   云原生的重要属性包括(事实上从应用的开发、部署和运维三个方面说明了云原生应用的特点)：

   - 应用即代码(系统资源)：应用即代码，简单来说，就是通过代码(配置文件)进行应用的部署。云平台下，应用部署和运行的一个核心目标是可重现性，即在不同场景下可复制应用的运行环境、自动化部署应用，且重现应用的运行状态。

     应用即代码的基础是基础设施即代码。通过使用代码来定义计算、存储和网络等基础设施，使得基础设施配置有了可回溯性和一致性。一致性是指使用同样的代码，我们可以获得相同的基础设施和运行环境，避免了人为操作有误导致问题的出现(也可以说是确定性，即通过某个代码定义和配置出的基础设施是确定的，规定了其计算、存储和网络等资源以及内部环境)。可回溯性是指基础设施的配置可以被存储，当新的设施出现问题时，可以快速回滚，不容易受到错误的记录的影响。基础设施即代码的一个重要例子是Docker中使用Dockerfile直接通过代码完成镜像构建(镜像没有进行资源的分配，但是其定义了应用的运行环境。资源分配的例子是通过代码构建虚拟机)

     除了基础设施即代码，应用即代码还需要通过代码实现应用本身的部署，包括应用的启动指令、确定应用的运行参数、应用的运行状态、应用的生命周期管理等。采用容器编排的方法是代码部署应用的最佳实践。例如Kubernetes中的Pod代表应用，我们只需要使用YAML文件定义Pod的内容，并提交到Kubernetes平台中，就可以自动化构建和部署应用，并由Kubernetes平台进行容器生命周期的管理。应用即代码使得在基础设施一致的情况下，我们使用相同的代码配置文件能够获得具有相同属性的应用

   - 演进式架构(应用架构)：应用需要采用与时俱进的演进式架构，确保在当下的需求得到满足的同时，支持未来的变更和重构，以应对未来的需要。应用重构可以由企业对领域的深入理解(理解、需求上的细化)，以及对模型及其代码表达式进行相应的精化(技术上的演进)所推动。应用在开发之初，就应当考虑以功能实现更容易、修改更简单、扩展更轻松的架构进行设计。

     演进式架构需要考虑如下4个方面
   
     - 解耦性：应用设计应当理解各个业务模块、功能模块等的划分和关联，设计出耦合性低的应用架构。清晰解耦的应用易于演进，充满耦合性的应用则会妨碍演进
     - 增量变更：具备功能级别的扩展性
     - 决策后置：延后技术选型、运行管理等决策，将应用架构与实现方式、运行方式、运维模式解耦，优先考虑应用架构设计
     - 引导性：应用架构对于应用的演进具备指导意义
   
   - 全生命周期管理(软件工程)：
   
     云原生应用开发的团队组织方面，云原生应用通过划分清晰的基于业务逻辑的模块边界，将应用划分为多个具备独立部署、与开发语言无关能力的服务，这要求各个服务的团队应当包含UI人员、后端开发人员、DBA和项目经理等
   
     云原生应用的开发和运维方面，应用的运维不仅需要保证应用的正常运行，还希望在运行过程中获取相关数据作为反馈，从而持续地开发和优化应用，实现DevOps中所提倡的IT价值流的反馈。全生命周期管理希望通过精益思想、自动化的流水线，来完善应用的设计、开发、运维、运营的各个步骤，覆盖应用的全生命周期
   
     **问题：通过流水线来完善应用生命周期的各个步骤，具体是什么样的？**
   
6. 云原生关键技术

   - 不可变基础设施(容器)：传统的服务器架构中，服务器状态会被不断地更新和修改，其内部配置文件和软件包会被调整。这导致发生灾难时，需要大量手工操作重构服务，且服务器状态修改引入了中间状态，可能出现不可预知的问题。不可变基础设施指的是任何的基础设施实例一旦进行创建后，其内部内容将成为只读状态，如果要更改则需要整个基础设施进行替换。例如，某些应用实例的升级或更新采用的方法是直接用新的一批实例进行替换。从运维的角度看，整个基础设施处于可预计的、不可变的状态，且基础设施的变更是可以被记录的(采用应用即代码和基础设施即代码，借助容器技术和镜像技术)

   - 声明式编排(Kubernetes)：命令式API通过直接发出服务器要执行的指令，使服务器完成相应操作；声明式API将运行环境、配置信息等通过事先约定的描述方式记录在文档中，描述系统的终态。编排器根据预先定义的编排模板，结合用户声明的应用内容和系统终态，利用控制器自动化进行应用的构建和部署，使系统达到用户预期的状态。声明式编排避免了手动操作带来的不确定性，且其自动化特点大大简化了应用的运维和系统的维护

   - 微服务架构：通过采用微服务架构，使应用划分为多个微服务，明确微服务的边界，将应用解耦，获得易于演进、容易变更的应用

   - 动态赋能(服务网格)：为了保持应用轻量化的需求，使应用专注于业务逻辑的功能，应当在应用运行时为其进行动态赋能，使其具备流量监控、鉴权、负载均衡、安全日志等功能，令其能够顺利地与云平台衔接，利用云平台提供的服务。服务网格的流量透明劫持是目前比较认可的动态赋能方式，在应用部署在服务网格中时，动态地在应用服务所在的Pod中插入Sidecar容器，为服务提供各种能力

   - 适应度函数(引导性)：适应度函数是一个目标函数(类似于线性规划中的不等式)，用于计算应用架构等非功能性属性与既定目标的差距，使整个应用架构朝着某个目标变化。每个适应度函数对应了架构的一个或多个维度的需求，而全系统的适应度函数表示了这些函数的集合，其通过有选择地验证不同的维度，提供比较和评估不同架构特性的基础。设置适应度函数是用于防止架构被破坏，最终确保架构以有效的方式演进

     适应度函数的个人理解就是对每个架构维度确定一种评判标准，以及整体架构的最终目标，在架构演进的过程中采用正确地评估方法评价新的架构在各个指标上的表现以及整体的性能，确保总体架构按期望的方向发展

   - 领域驱动建模

   - CI/CD/CO

7. 云原生应用的实现阶段

   - 对于非云原生场景，由于云平台只能提供非常有限的功能，因此应用需要自行实现非业务逻辑功能
   - 较理想的云原生下，云平台可以提供大部分功能，在轻量化应用上具有明显的改观，但仍然存在部分能力云平台无法提供的情况
   - 理论上理想的云原生，是云平台能够提供业务功能外的所有能力，应用的所有环节也能完全进行解耦，使得应用能够完全的与云平台协同，完全依赖云平台提供的功能

   云原生的不断推进，是云平台功能的不断增加和优化，也是应用架构的不断更替。只有云平台能够提供足够的能力，应用能以原生的形态设计，才能充分发挥云平台的优势
